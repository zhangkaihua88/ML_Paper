{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T14:52:52.279790Z",
     "start_time": "2020-02-06T14:52:07.838857Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "\n",
    "tf.random.set_seed(22)\n",
    "np.random.seed(22)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "assert tf.__version__.startswith('2.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T14:52:52.314698Z",
     "start_time": "2020-02-06T14:52:52.299738Z"
    }
   },
   "outputs": [],
   "source": [
    "#该函数用于输出生成图片\n",
    "def plot(samples, sample_count=sample_count):\n",
    "    fig = plt.figure(figsize=(sample_count, sample_count))\n",
    "    gs = gridspec.GridSpec(sample_count, sample_count)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(tf.reshape(sample,(28, 28)), cmap='Greys_r')\n",
    "        \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T14:52:52.293755Z",
     "start_time": "2020-02-06T14:52:52.284778Z"
    }
   },
   "outputs": [],
   "source": [
    "# 参数设置\n",
    "batchsz = 100\n",
    "z_dim = 100\n",
    "learning_rate = 1e-4\n",
    "is_training = True\n",
    "epochs = 30000\n",
    "sample_count = 10\n",
    "network_path = \"E:\\\\C_all\\\\Desktop\\\\深度之眼\\\\paper\\\\tensorflow\\\\文献实现\\\\GAN\\\\模型输出\\\\CGAN\\\\\"\n",
    "img_path = \"E:\\\\C_all\\\\Desktop\\\\深度之眼\\\\paper\\\\tensorflow\\\\文献实现\\\\GAN\\\\out\\\\\"\n",
    "if not os.path.exists(img_path):\n",
    "    os.makedirs(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T14:52:52.393487Z",
     "start_time": "2020-02-06T14:52:52.320682Z"
    }
   },
   "outputs": [],
   "source": [
    "class Maxoutlayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, k, m):\n",
    "        super(Maxoutlayer, self).__init__()\n",
    "        self.k = int(k)\n",
    "        self.m = int(m)\n",
    "\n",
    "    def build(self, input_shape, dtype=tf.float32):\n",
    "        self.d = input_shape[-1]\n",
    "        print(self.d,input_shape)\n",
    "        self.w = self.add_weight(name='w',\n",
    "                                 shape=(self.d, self.m, self.k),\n",
    "                                 initializer='uniform',\n",
    "                                 dtype=dtype,\n",
    "                                 trainable=True)\n",
    "        self.b = self.add_weight(name='b',\n",
    "                                 shape=(self.m, self.k),\n",
    "                                 initializer='zero',\n",
    "                                 dtype=dtype,\n",
    "                                 trainable=True)\n",
    "        super(Maxoutlayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        outputs = tf.tensordot(x, self.w, axes=1) + self.b\n",
    "        outputs = tf.reduce_max(outputs, axis=2)\n",
    "        return outputs\n",
    "class Generator(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "#         self.dense1 = keras.layers.Dense(128) # 正常dense\n",
    "        self.dense1 = Maxoutlayer(5, 128) # maxoutlayer\n",
    "        self.dense2 = keras.layers.Dense(784)\n",
    "\n",
    "    def call(self, z, y, training=None):\n",
    "        zy = tf.concat([z, y], axis=1)\n",
    "        g_1 = tf.nn.elu(self.dense1(zy))\n",
    "        mean,variance = tf.nn.moments(g_1,-1) # maxoutlayer\n",
    "        g_1 = (g_1 - tf.reshape(mean,(batchsz,-1))) / tf.reshape(variance**0.5,(batchsz,-1)) # maxoutlayer\n",
    "        g_2 = tf.nn.sigmoid(self.dense2(g_1))\n",
    "        return g_2\n",
    "\n",
    "\n",
    "class Discriminator(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.dense1 = keras.layers.Dense(128)\n",
    "        self.dense2 = keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, x, y, training=None):\n",
    "        xy = tf.concat([x, y], axis=1)\n",
    "        d_1 = tf.nn.elu(self.dense1(xy))\n",
    "        d_logit = self.dense2(d_1)\n",
    "        d_prob = tf.nn.sigmoid(d_logit)\n",
    "        return d_prob, d_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T14:52:52.405456Z",
     "start_time": "2020-02-06T14:52:52.397476Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_z(m, n):\n",
    "    return tf.random.uniform(maxval=1., minval=-1., shape=[m, n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T14:52:54.119044Z",
     "start_time": "2020-02-06T14:52:52.410442Z"
    }
   },
   "outputs": [],
   "source": [
    "(x, y),(x_val,y_val) = keras.datasets.mnist.load_data()\n",
    "\n",
    "x = tf.convert_to_tensor(x, dtype=tf.float32)/255.\n",
    "x = tf.reshape(x,(-1, 28*28))\n",
    "y = tf.convert_to_tensor(y, dtype=tf.int32)\n",
    "y_onehot = tf.one_hot(y, depth=10) # one_hot成立\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x,y_onehot)).repeat(-1).batch(batchsz)\n",
    "train_dbiter = iter(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T14:52:54.164879Z",
     "start_time": "2020-02-06T14:52:54.125983Z"
    }
   },
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "g_optimizer = tf.optimizers.Adam(learning_rate=learning_rate)\n",
    "d_optimizer = tf.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T14:52:54.313481Z",
     "start_time": "2020-02-06T14:52:54.283562Z"
    }
   },
   "outputs": [],
   "source": [
    "# 交叉熵损失函数\n",
    "def celoss_ones(logits):\n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,labels=tf.ones_like(logits))\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "def celoss_zeros(logits):\n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=tf.zeros_like(logits))\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "def d_loss_fn(generator, discriminator, batch_z, batch_x, batch_y, is_training):\n",
    "    fake_data = generator(batch_z, batch_y, is_training)\n",
    "    d_real,d_real_logits = discriminator(batch_x, batch_y, is_training)\n",
    "    d_fake,d_fake_logits = discriminator(fake_data, batch_y, is_training)\n",
    "    d_loss_real = celoss_ones(d_real_logits)\n",
    "    d_loss_fake = celoss_zeros(d_fake_logits)\n",
    "    d_loss = d_loss_fake + d_loss_real\n",
    "    return d_loss\n",
    "\n",
    "def g_loss_fn(generator, discriminator, batch_z, batch_y, is_training):\n",
    "    fake_data = generator(batch_z, batch_y, is_training)\n",
    "    d_fake,d_fake_logits = discriminator(fake_data, batch_y, is_training)\n",
    "    g_loss = celoss_ones(d_fake_logits)\n",
    "    return g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T14:52:54.369332Z",
     "start_time": "2020-02-06T14:52:54.351381Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_image(label, generator, m=sample_count**2, n=z_dim):\n",
    "    sample_y = tf.one_hot(list(range(10)) * 10,depth=10,dtype=tf.float32)\n",
    "    z = sample_z(m, n)\n",
    "    fake_images = generator(z,sample_y)\n",
    "    fig = plot(fake_images)\n",
    "    plt.savefig(img_path + \"{}.png\".format(label),bbox_inches=\"tight\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T14:52:54.405239Z",
     "start_time": "2020-02-06T14:52:54.384293Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_weights_(generator, discriminator, network_path=network_path):\n",
    "    if not os.path.exists(img_path):\n",
    "        os.makedirs(img_path)\n",
    "    generator.save_weights(network_path+\"cgan_g\")\n",
    "    discriminator.save_weights(network_path+\"cgan_d\")\n",
    "    print(\"saved total weights.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-06T14:52:07.955Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 (100, 110)\n",
      "saved total weights.\n",
      "0 d-loss: 1.5539416074752808 g-loss: 1.0622875690460205\n",
      "\n",
      "saved total weights.\n",
      "1000 d-loss: 0.5798658132553101 g-loss: 1.7094054222106934\n",
      "\n",
      "saved total weights.\n",
      "2000 d-loss: 0.7365269064903259 g-loss: 1.2456793785095215\n",
      "\n",
      "saved total weights.\n",
      "3000 d-loss: 0.42904508113861084 g-loss: 1.7211616039276123\n",
      "\n",
      "saved total weights.\n",
      "4000 d-loss: 0.20582297444343567 g-loss: 2.4959986209869385\n",
      "\n",
      "saved total weights.\n",
      "5000 d-loss: 0.20742002129554749 g-loss: 2.54160213470459\n",
      "\n",
      "saved total weights.\n",
      "6000 d-loss: 0.10852529108524323 g-loss: 3.3190321922302246\n",
      "\n",
      "saved total weights.\n",
      "7000 d-loss: 0.13999749720096588 g-loss: 3.1363685131073\n",
      "\n",
      "saved total weights.\n",
      "8000 d-loss: 0.22361893951892853 g-loss: 2.5899996757507324\n",
      "\n",
      "saved total weights.\n",
      "9000 d-loss: 0.38055890798568726 g-loss: 2.4479100704193115\n",
      "\n",
      "saved total weights.\n",
      "10000 d-loss: 0.5953718423843384 g-loss: 1.8801110982894897\n",
      "\n",
      "saved total weights.\n",
      "11000 d-loss: 0.5042920112609863 g-loss: 1.9203633069992065\n",
      "\n",
      "saved total weights.\n",
      "12000 d-loss: 0.6020327806472778 g-loss: 1.6190762519836426\n",
      "\n",
      "saved total weights.\n",
      "13000 d-loss: 0.5992844700813293 g-loss: 1.6742802858352661\n",
      "\n",
      "saved total weights.\n",
      "14000 d-loss: 0.668434202671051 g-loss: 1.5344651937484741\n",
      "\n",
      "saved total weights.\n",
      "15000 d-loss: 0.7784420251846313 g-loss: 1.3279600143432617\n",
      "\n",
      "saved total weights.\n",
      "16000 d-loss: 0.8620362877845764 g-loss: 1.2813471555709839\n",
      "\n",
      "saved total weights.\n",
      "17000 d-loss: 0.8236715197563171 g-loss: 1.3074489831924438\n",
      "\n",
      "saved total weights.\n",
      "18000 d-loss: 1.0594438314437866 g-loss: 1.1677536964416504\n",
      "\n",
      "saved total weights.\n",
      "19000 d-loss: 1.005087971687317 g-loss: 1.1227058172225952\n",
      "\n",
      "saved total weights.\n",
      "20000 d-loss: 0.8136482238769531 g-loss: 1.2403587102890015\n",
      "\n",
      "saved total weights.\n",
      "21000 d-loss: 1.0980002880096436 g-loss: 1.1289101839065552\n",
      "\n",
      "saved total weights.\n",
      "22000 d-loss: 1.044130563735962 g-loss: 1.0664780139923096\n",
      "\n",
      "saved total weights.\n",
      "23000 d-loss: 0.9863889813423157 g-loss: 1.041346788406372\n",
      "\n",
      "saved total weights.\n",
      "24000 d-loss: 1.243344783782959 g-loss: 0.949710488319397\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs+1):\n",
    "    batch_z = sample_z(batchsz, z_dim)\n",
    "    batch_x, batch_y = next(train_dbiter)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        d_loss = d_loss_fn(generator, discriminator, batch_z, batch_x, batch_y, is_training)\n",
    "    grads = tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "    d_optimizer.apply_gradients(zip(grads, discriminator.trainable_variables))\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        g_loss = g_loss_fn(generator, discriminator, batch_z, batch_y, is_training)\n",
    "    grads = tape.gradient(g_loss, generator.trainable_variables)\n",
    "    g_optimizer.apply_gradients(zip(grads, generator.trainable_variables))\n",
    "    \n",
    "#     if learning_rate >= 0.000001:\n",
    "#         learning_rate -= learning_rate*0.00004\n",
    "    \n",
    "    if epoch % 1000 == 0:\n",
    "        save_image(str(epoch), generator)\n",
    "        save_weights_(generator, discriminator)\n",
    "        print(epoch, 'd-loss:', float(d_loss), 'g-loss:', float(g_loss))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-06T14:46:43.130Z"
    }
   },
   "outputs": [],
   "source": [
    "# # 在custom layer中的 call() 上添加 @tf.function 可以将前向传播过程中不属于Graph的部分 转化为Graph。\n",
    "# network_path = \"E:\\\\C_all\\\\Desktop\\\\深度之眼\\\\paper\\\\tensorflow\\\\文献实现\\\\GAN\\\\模型输出\\\\\"\n",
    "# generator.save_weights(network_path+\"original_gan_g\")\n",
    "# discriminator.save_weights(network_path+\"original_gan_d\")\n",
    "# print(\"saved total weights.\")\n",
    "del generator\n",
    "del discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "save_image(\"载入前\",generator)\n",
    "# generator.load_weights(network_path+\"cgan_g\")\n",
    "# discriminator.load_weights(network_path+\"cgan_d\")\n",
    "# save_image(\"载入后\",generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MLCPUfor3.7]",
   "language": "python",
   "name": "conda-env-MLCPUfor3.7-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
