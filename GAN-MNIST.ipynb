{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T15:38:30.432841Z",
     "start_time": "2020-02-04T15:38:30.397966Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec \n",
    "\n",
    "import os\n",
    "\n",
    "tf.random.set_seed(22)\n",
    "np.random.seed(22)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "assert tf.__version__.startswith('2.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T15:58:16.898412Z",
     "start_time": "2020-02-04T15:58:16.890434Z"
    }
   },
   "outputs": [],
   "source": [
    "#参数设置\n",
    "batchsz = 128\n",
    "z_dim = 100\n",
    "learning_rate = 1e-4\n",
    "is_training = True\n",
    "epochs = 30000\n",
    "sample_count=4\n",
    "network_path = \"E:\\\\C_all\\\\Desktop\\\\深度之眼\\\\paper\\\\tensorflow\\\\文献实现\\\\GAN\\\\模型输出\\\\GAN\\\\\"\n",
    "img_path = \"E:\\\\C_all\\\\Desktop\\\\深度之眼\\\\paper\\\\tensorflow\\\\文献实现\\\\GAN\\\\out\\\\\"\n",
    "if not os.path.exists(img_path):\n",
    "    os.makedirs(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T15:53:56.764915Z",
     "start_time": "2020-02-04T15:53:56.340806Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gs = gridspec.GridSpec(2, 2)\n",
    "ax = plt.subplot(gs[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T15:53:56.792594Z",
     "start_time": "2020-02-04T15:53:56.772649Z"
    }
   },
   "outputs": [],
   "source": [
    "#该函数用于输出生成图片\n",
    "def plot(samples, sample_count=sample_count):\n",
    "    fig = plt.figure(figsize=(sample_count, sample_count))\n",
    "    gs = gridspec.GridSpec(sample_count, sample_count)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(tf.reshape(sample*255.,(28, 28)), cmap='Greys_r')\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T15:53:57.004031Z",
     "start_time": "2020-02-04T15:53:56.984083Z"
    }
   },
   "outputs": [],
   "source": [
    "class Generator(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.dense1 = keras.layers.Dense(128)\n",
    "        self.dense2 = keras.layers.Dense(784)\n",
    "    @tf.function\n",
    "    def call(self, inputs, training=None):\n",
    "        g_1 = tf.nn.relu(self.dense1(inputs))\n",
    "        g_logit = self.dense2(g_1)\n",
    "        g = tf.nn.sigmoid(g_logit)\n",
    "        return g\n",
    "\n",
    "class Discriminator(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.dense1 = keras.layers.Dense(128)\n",
    "        self.dense2 = keras.layers.Dense(1)\n",
    "    @tf.function\n",
    "    def call(self, inputs, training=None):\n",
    "        d_1 = tf.nn.relu(self.dense1(inputs))\n",
    "        d_logit = self.dense2(d_1)\n",
    "        #真(=1)，假(=0)\n",
    "        d_prob = tf.nn.sigmoid(d_logit)\n",
    "        return d_prob, d_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T15:54:39.988166Z",
     "start_time": "2020-02-04T15:54:39.977196Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_z(m, n):\n",
    "    return tf.random.uniform(maxval=1., minval=-1., shape=[m, n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T15:53:59.919235Z",
     "start_time": "2020-02-04T15:53:57.732083Z"
    }
   },
   "outputs": [],
   "source": [
    "# keras.datasets.mnist.load_data()输出类型为tuple->array，tuple结构（2，2）\n",
    "# x结构为(60000,28,28),y结构为(60000,),dtype为uint8\n",
    "# x结构为(10000,28,28),y结构为(10000,),dtype为uint8\n",
    "(x, y),(x_val,y_val) = keras.datasets.mnist.load_data()\n",
    "\n",
    "x = tf.convert_to_tensor(x, dtype=tf.float32)/255.\n",
    "x = tf.reshape(x,(-1, 28*28))\n",
    "y = tf.convert_to_tensor(y, dtype=tf.int32)\n",
    "y_onehot = tf.one_hot(y, depth=10) # one_hot成立\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x,y)).repeat(-1).batch(batchsz)\n",
    "train_dbiter = iter(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T15:54:00.246404Z",
     "start_time": "2020-02-04T15:53:59.929205Z"
    }
   },
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "generator.build(input_shape=(None, z_dim))\n",
    "discriminator = Discriminator()\n",
    "discriminator.build(input_shape=(None, 784))\n",
    "\n",
    "g_optimizer = tf.optimizers.Adam(learning_rate=learning_rate)\n",
    "d_optimizer = tf.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T15:54:00.278274Z",
     "start_time": "2020-02-04T15:54:00.256333Z"
    }
   },
   "outputs": [],
   "source": [
    "# 原始判别器和生成器损失\n",
    "def d_loss_fn(generator, discriminator, batch_z, batch_x, is_training):\n",
    "    fake_data = generator(batch_z, is_training)\n",
    "    d_real,d_logit = discriminator(batch_x, is_training)\n",
    "    d_fake,d_logit = discriminator(fake_data, is_training)\n",
    "    d_loss = -tf.reduce_mean(tf.math.log(d_real) + tf.math.log(1. - d_fake))\n",
    "    return d_loss\n",
    "def g_loss_fn(generator, discriminator, batch_z, is_training):\n",
    "    fake_data = generator(batch_z, is_training)\n",
    "    d_fake,d_logit = discriminator(fake_data, is_training)\n",
    "    g_loss = -tf.reduce_mean(tf.math.log(d_fake))\n",
    "    return g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T15:54:00.302254Z",
     "start_time": "2020-02-04T15:54:00.288260Z"
    }
   },
   "outputs": [],
   "source": [
    "# # 交叉熵损失函数\n",
    "# def celoss_ones(logits):\n",
    "#     loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,labels=tf.ones_like(logits))\n",
    "#     return tf.reduce_mean(loss)\n",
    "\n",
    "\n",
    "# def celoss_zeros(logits):\n",
    "#     loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=tf.zeros_like(logits))\n",
    "#     return tf.reduce_mean(loss)\n",
    "\n",
    "# def d_loss_fn(generator, discriminator, batch_z, batch_x, is_training):\n",
    "#     fake_data = generator(batch_z, is_training)\n",
    "#     d_real,d_real_logits = discriminator(batch_x, is_training)\n",
    "#     d_fake,d_fake_logits = discriminator(fake_data, is_training)\n",
    "#     d_loss_real = celoss_ones(d_real_logits)\n",
    "#     d_loss_fake = celoss_zeros(d_fake_logits)\n",
    "#     d_loss = d_loss_fake + d_loss_real\n",
    "#     return d_loss\n",
    "# def g_loss_fn(generator, discriminator, batch_z, is_training):\n",
    "#     fake_data = generator(batch_z, is_training)\n",
    "#     d_fake,d_fake_logits = discriminator(fake_data, is_training)\n",
    "#     g_loss = celoss_ones(d_fake_logits)\n",
    "#     return g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T15:57:34.594055Z",
     "start_time": "2020-02-04T15:57:34.585070Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_image(label, generator, m=sample_count**2, n=z_dim):\n",
    "    z = sample_z(m, n)\n",
    "    fake_images = generator(z)\n",
    "    fig = plot(fake_images)\n",
    "    plt.savefig(img_path + \"{}.png\".format(label),bbox_inches=\"tight\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T16:00:24.469462Z",
     "start_time": "2020-02-04T16:00:24.458533Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_weights_(generator, discriminator, network_path=network_path):\n",
    "    if not os.path.exists(img_path):\n",
    "        os.makedirs(img_path)\n",
    "    generator.save_weights(network_path+\"cgan_g\")\n",
    "    discriminator.save_weights(network_path+\"cgan_d\")\n",
    "    print(\"saved total weights.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T16:02:29.758452Z",
     "start_time": "2020-02-04T16:00:47.588054Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved total weights.\n",
      "0 d-loss: 0.13402806222438812 g-loss: 3.2582359313964844\n",
      "\n",
      "saved total weights.\n",
      "1000 d-loss: 0.15404126048088074 g-loss: 3.390033721923828\n",
      "\n",
      "saved total weights.\n",
      "2000 d-loss: 0.17004743218421936 g-loss: 3.2146859169006348\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# for step, (batch_x, batch_y) in enumerate(train_dataset):\n",
    "#     batch_z = sample_z(batchsz, z_dim)\n",
    "for epoch in range(epochs+1):\n",
    "    batch_z = sample_z(batchsz, z_dim)\n",
    "    batch_x, batch_y = next(train_dbiter)\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        d_loss = d_loss_fn(generator, discriminator, batch_z, batch_x, is_training)\n",
    "    grads = tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "    d_optimizer.apply_gradients(zip(grads, discriminator.trainable_variables))\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        g_loss = g_loss_fn(generator, discriminator, batch_z, is_training)\n",
    "    grads = tape.gradient(g_loss, generator.trainable_variables)\n",
    "    g_optimizer.apply_gradients(zip(grads, generator.trainable_variables))\n",
    "    \n",
    "    if epoch % 1000 == 0:\n",
    "        save_image(str(epoch), generator)\n",
    "        save_weights_(generator, discriminator)\n",
    "        print(epoch, 'd-loss:', float(d_loss), 'g-loss:', float(g_loss))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T16:04:32.328649Z",
     "start_time": "2020-02-04T16:04:29.525016Z"
    }
   },
   "outputs": [],
   "source": [
    "# # 在custom layer中的 call() 上添加 @tf.function 可以将前向传播过程中不属于Graph的部分 转化为Graph。\n",
    "# network_path = \"E:\\\\C_all\\\\Desktop\\\\深度之眼\\\\paper\\\\tensorflow\\\\文献实现\\\\GAN\\\\模型输出\\\\\"\n",
    "# generator.save_weights(network_path+\"original_gan_g\")\n",
    "# discriminator.save_weights(network_path+\"original_gan_d\")\n",
    "# print(\"saved total weights.\")\n",
    "del generator\n",
    "del discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "save_image(\"载入前\",generator)\n",
    "generator.load_weights(network_path+\"original_gan_g\")\n",
    "discriminator.load_weights(network_path+\"original_gan_d\")\n",
    "save_image(\"载入后\",generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MLCPUfor3.7]",
   "language": "python",
   "name": "conda-env-MLCPUfor3.7-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
